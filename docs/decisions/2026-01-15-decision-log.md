# Decision Log — 2026-01-15

## 1) LLM внутри продукта (обязателен)
Дата: 2026-01-15  
Тема: LLM requirement  
Контекст: генерация должна использовать LLM, при этом оставаться предсказуемой и дешёвой.  
Варианты (A/B/C):  
- A: no LLM (templates only)  
- B: LLM everywhere (freeform)  
- C: template-based + LLM  
Выбор: C  
Причина: качество и гибкость при контролируемой стоимости/предсказуемости.  
Компромиссы/риски: нужен контроль токенов/кэша и приватности данных.  
Что проверяем завтра (design-pass): какие данные уходят в LLM и какие нет.

## 2) LLM-пайплайн: “дрова” → template-based
Дата: 2026-01-15  
Тема: Two-stage LLM pipeline  
Контекст: нужны “факты” из данных + устойчивое форматирование под вкус.  
Варианты (A/B/C):  
- A: один вызов LLM (из данных сразу в пост)  
- B: два вызова LLM (signals → render)  
- C: без LLM для сигналов (regex/heuristics)  
Выбор: B  
Причина: лучше отделяет извлечение фактов от рендеринга под вкус.  
Компромиссы/риски: +1 LLM вызов → нужна экономия (кэш/батч).  
Что проверяем завтра (design-pass): минимум входных данных для “дров”.

## 3) GitHub подключение: OAuth, только public repos (MVP)
Дата: 2026-01-15  
Тема: GitHub auth scope for MVP  
Контекст: paки должны быть “с информацией”, но MVP должен быть простым и безопасным.  
Варианты (A/B/C):  
- A: GitHub OAuth public-only  
- B: GitHub OAuth для private repos  
- C: PAT/ручные токены  
Выбор: A  
Причина: минимальные риски и меньше UX/безопасность проблем в MVP.  
Компромиссы/риски: часть пользователей с приватными репами не сможет использовать.  
Что проверяем завтра (design-pass): UX выбора реп и объяснение ограничения public-only.

## 4) Выбор репозиториев: вручную чеклистом
Дата: 2026-01-15  
Тема: Repo selection UX  
Контекст: избегаем “авто-подключения” и сюрпризов.  
Варианты (A/B/C):  
- A: пользователь сам выбирает репы  
- B: авто-выбор последних N + исключения  
- C: один репо на старте  
Выбор: A  
Причина: контроль и приватность по умолчанию.  
Компромиссы/риски: больше шагов в onboarding.  
Что проверяем завтра (design-pass): как сделать шаг “Select repos” быстрым.

## 5) Данные из репозиториев: только commit messages + метаданные (без diff/кода)
Дата: 2026-01-15  
Тема: Data minimization for MVP  
Контекст: защищаем код и снижаем риск утечки в LLM.  
Варианты (A/B/C):  
- A: messages + метаданные  
- B: messages + список файлов + summary без кода  
- C: полный diff  
Выбор: A  
Причина: минимальный риск и простая интеграция.  
Компромиссы/риски: меньше контекста → нужно лучшее извлечение “фактов” из messages.  
Что проверяем завтра (design-pass): какие форматы commit messages дают лучший результат.

## 6) Стек MVP: Vite/React PWA + Supabase + Edge Functions
Дата: 2026-01-15  
Тема: Stack decision (MVP)  
Контекст: нужен быстрый цикл итераций, PWA, надёжный ship-flow, и безопасные LLM вызовы (ключи не в клиенте).  
Варианты (A/B/C):  
- A: Vite + React + TS (PWA) + Supabase + Supabase Edge Functions  
- B: Next.js + Supabase (SSR/functions)  
- C: нативное приложение  
Выбор: A  
Причина: минимальная сложность и совпадает с текущим `PLAN.md`, при этом Edge Functions закрывают серверную часть для LLM.  
Компромиссы/риски: OAuth нюансы в SPA решаются через Supabase Auth; серверные прокси к GitHub можно добавить позже при необходимости.  
Что проверяем завтра (design-pass): UX GitHub connect + repo picker на мобиле.

## 7) GitHub данные: читать с клиента по provider token (MVP)
Дата: 2026-01-15  
Тема: GitHub API access path  
Контекст: нужны public repos и commits, без хранения токенов в БД и без лишних прокси.  
Варианты (A/B/C):  
- A: клиент ходит напрямую в GitHub API с provider token из Supabase session  
- B: Edge Function проксирует GitHub API (нужно передавать/доставать token на сервере)  
- C: хранить PAT/токены в БД (не хотим)  
Выбор: A  
Причина: меньше инфраструктуры и рисков хранения; токен остаётся “пользовательским” и живёт в сессии.  
Компромиссы/риски: нужно аккуратно обращаться с токеном в клиенте; rate limits решаем кэшем и ограничениями N.  
Что проверяем завтра (design-pass): понятные ошибки rate limit и повторная авторизация.

## 8) LLM провайдеры: абстракция + переменные окружения
Дата: 2026-01-15  
Тема: LLM provider strategy  
Контекст: 2-stage пайплайн (facts → render) и требование контролировать стоимость.  
Варианты (A/B/C):  
- A: один провайдер на оба слоя (проще)  
- B: разные провайдеры по слоям (качество/цена)  
- C: провайдер жёстко прошит в коде  
Выбор: A (с возможностью перейти на B без рефактора)  
Причина: MVP быстрее; делаем интерфейс “LLM client” и настройки через env, чтобы потом безболезненно разделить слои.  
Компромиссы/риски: возможно переплата на старте; решаем лимитами и кэшем.  
Что проверяем завтра (design-pass): какие лимиты/батчи дают приемлемый результат по карточкам.
